# YouTube to Shorts Service

A full-stack web application that converts YouTube videos into engaging short clips using AI-powered video processing.

## âš¡ Quick Start

**First time setup? Choose your setup method:**

### ğŸš€ For Restricted/Corporate Environments (Recommended)
```bash
# Minimal setup that works in most environments:
./setup-minimal.sh
```

### ğŸ”§ For Full Development Environment
```bash
# Complete setup with all video processing features:
./setup.sh
```

**Then start all services:**

```bash
# From the project root directory:
./start.sh
```

That's it! ğŸ‰ The setup script handles dependencies, and start script launches everything.

- **Frontend**: http://localhost:3000
- **Backend**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

Press `Ctrl+C` to stop all services.

---

## ğŸ¯ Overview

This service consists of three main components:

- **Backend**: FastAPI server that handles video processing requests and serves generated clips
- **Frontend**: Next.js web interface for submitting videos and viewing results  
- **Video Processor**: Python modules for video processing (already exists in `ml_stuff/processors/`)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    API calls    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Calls    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚                 â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚                 â”‚
â”‚  Next.js        â”‚                 â”‚  FastAPI        â”‚             â”‚  ml_stuff/      â”‚
â”‚  Frontend       â”‚ â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚  Backend        â”‚ â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚  processors/    â”‚
â”‚  (port 3000)    â”‚   Video clips   â”‚  (port 8000)    â”‚  Results    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Prerequisites

Before setting up the frontend and backend, ensure you have:

1. **Python 3.8+** with pip
2. **Node.js 18+** with npm
3. **Video Processing Modules**: The `ml_stuff/processors/` directory contains your existing video processing code

### Video Processing Modules

Your existing video processing code in `ml_stuff/processors/` includes:
- `transcribe.py` - Video transcription using Whisper
- `segments.py` - Segment detection and scoring using transformers
- `captions.py` - Caption generation using OpenAI API

The backend integrates these modules with additional functionality:
- `ml_stuff/pipeline.py` - Complete pipeline wrapper that downloads YouTube videos, processes them, and creates video clips

### Required Dependencies

The system requires several Python packages for video processing:
- **yt-dlp** - For downloading YouTube videos
- **moviepy** - For creating video clips
- **whisper** - For audio transcription
- **transformers** - For sentiment analysis
- **pydub** - For audio processing
- **openai** - For caption generation (requires API key)

### Environment Variables

For full functionality, set these environment variables:
- `OPENAI_API_KEY` - Required for caption generation (optional, will work without captions)

## ğŸš€ Setup Instructions

### ğŸ¯ Choose Your Setup Method

#### **Option 1: Minimal Setup (Recommended for Most Users)**

Perfect for restricted environments, corporate networks, or quick testing:

```bash
# Minimal setup that works everywhere:
./setup-minimal.sh
```

This will install:
- âœ… FastAPI web server and core dependencies
- âœ… Frontend React/Next.js components  
- âœ… Basic API functionality with mock data
- âœ… Core video processing pipeline (limited functionality)

#### **Option 2: Complete Setup (Full Features)**

For full development with all video processing capabilities:

```bash
# Complete setup with all features:
./setup.sh
```

This will additionally install:
- âœ… PyTorch and AI/ML libraries
- âœ… Video processing tools (requires ffmpeg)
- âœ… Real transcription and video editing
- âœ… Full OpenAI integration

**Then start the services:**
```bash
./start.sh
```

### ğŸ”§ Manual Setup (If Needed)

If you prefer to set up manually or need to troubleshoot:

#### 1. Backend Setup

```bash
# Use make command for easy setup
make setup-backend

# OR manually:
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -e .
```

#### 2. Frontend Setup

```bash
# Use make command for easy setup
make setup-frontend

# OR manually:
cd frontend
npm install
```

## ğŸƒâ€â™‚ï¸ Running the Application

**ğŸ¯ EASY WAY - Single Command from Root Directory:**

You can now start both services with a single command from the project root:

### Option 1: Shell Script (Recommended)
```bash
./start.sh
```

### Option 2: NPM Script
```bash
npm start
# or
npm run dev
```

### Option 3: Make Command
```bash
make start
# or just
make
```

### Option 4: Node.js Script (with concurrently)
```bash
./dev.js
```

All of these commands will:
- âœ… Automatically check and install dependencies
- âœ… Start both backend and frontend servers
- âœ… Show colored output with service logs
- âœ… Handle graceful shutdown with Ctrl+C
- âœ… Display service URLs when ready

**ğŸ“ Service URLs:**
- Frontend: `http://localhost:3000`
- Backend: `http://localhost:8000`
- API Docs: `http://localhost:8000/docs`

---

**ğŸ”§ MANUAL WAY - Separate Terminals (if needed):**

### Terminal 1: Start the Backend Server

```bash
cd backend
source venv/bin/activate  # If using virtual environment
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### Terminal 2: Start the Frontend Server

```bash
cd frontend
npm run dev
```

## ğŸ® Usage

1. **Open your browser** and navigate to `http://localhost:3000`

2. **Enter a YouTube URL** in the first input field
   - Example: `https://www.youtube.com/watch?v=dQw4w9WgXcQ`

3. **Describe your clip requirements** in the prompt field
   - Example: "Create 3 engaging clips highlighting the main topics"
   - Example: "Extract funny moments and create 30-second clips"

4. **Click "Create Clips"** to start processing

5. **Monitor progress** - The interface will show real-time status updates

6. **View and download results** - Once complete, you can preview and download the generated clips

## ğŸ“ Project Structure

```
â”œâ”€â”€ README.md
â”œâ”€â”€ setup-minimal.sh            # ğŸš€ Minimal setup script (recommended)
â”œâ”€â”€ setup.sh                    # ğŸ”§ Complete setup script (full features)
â”œâ”€â”€ start.sh                    # ğŸš€ Main startup script (daily use)
â”œâ”€â”€ dev.js                      # ğŸ”§ Node.js development server
â”œâ”€â”€ package.json               # ğŸ“¦ Root package.json with scripts
â”œâ”€â”€ Makefile                   # ğŸ› ï¸ Make commands for development
â”œâ”€â”€ backend/                    # FastAPI Backend
â”‚   â”œâ”€â”€ pyproject.toml         # Python dependencies
â”‚   â”œâ”€â”€ .gitignore
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ main.py            # FastAPI app with endpoints
â”‚       â”œâ”€â”€ schemas.py         # Pydantic models
â”‚       â””â”€â”€ output_clips/      # Generated video clips
â”‚           â””â”€â”€ .gitkeep
â”œâ”€â”€ frontend/                   # Next.js Frontend
â”‚   â”œâ”€â”€ package.json           # Node.js dependencies
â”‚   â”œâ”€â”€ next.config.js
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ .gitignore
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ app/
â”‚       â”‚   â”œâ”€â”€ layout.tsx     # Root layout
â”‚       â”‚   â”œâ”€â”€ page.tsx       # Main page with form
â”‚       â”‚   â””â”€â”€ globals.css    # Global styles
â”‚       â””â”€â”€ services/
â”‚           â””â”€â”€ apiClient.ts   # API communication
â””â”€â”€ ml_stuff/                   # Video Processing (Your existing code)
    â”œâ”€â”€ processors/
    â”‚   â”œâ”€â”€ transcribe.py      # Video transcription
    â”‚   â”œâ”€â”€ segments.py        # Segment detection & scoring  
    â”‚   â””â”€â”€ captions.py        # Caption generation
    â”œâ”€â”€ test.py                # Test script for processors
    â””â”€â”€ zipline.mov            # Sample video file
```

## ğŸ›ï¸ Available Commands

### Setup Commands (Run Once)
```bash
./setup-minimal.sh  # Minimal setup for restricted environments (RECOMMENDED)
./setup.sh          # Complete setup with all video processing features
make setup-minimal  # Same as minimal setup
make setup          # Same as complete setup
npm run setup:minimal # Minimal setup via npm
npm run setup       # Complete setup via npm
make setup-quick    # Quick manual setup
```

### Start Commands (Daily Use)
```bash
./start.sh          # Start all services (recommended)
npm start           # Same as above, using npm
npm run dev         # Same as above, development mode
make start          # Using Make
make dev            # Same as above
./dev.js            # Node.js version with concurrently
```

### Development Commands
```bash
make setup-backend  # Setup only backend
make setup-frontend # Setup only frontend
make backend        # Run only backend server
make frontend       # Run only frontend server
make clean          # Clean all build artifacts
make logs           # View logs from running services
make help           # Show all available commands
```

### NPM Scripts (from root directory)
```bash
npm run setup:quick # Quick setup both services
npm run backend     # Run only backend
npm run frontend    # Run only frontend
npm run clean       # Clean project
npm run logs        # View logs
```

## ğŸ”§ API Endpoints

### Backend API (`http://localhost:8000`)

- `GET /` - Health check and API info
- `POST /process` - Start video processing
  ```json
  {
    "url": "https://youtube.com/watch?v=...",
    "prompt": "Create engaging clips..."
  }
  ```
- `GET /status/{job_id}` - Get processing status
- `GET /clips/{filename}` - Serve generated video files
- `GET /jobs` - List all jobs (debug endpoint)

## âš ï¸ Troubleshooting

### Setup Issues

**General setup problems or restricted environment**
```bash
# Try the minimal setup instead:
./setup-minimal.sh
# This works in most environments with fewer dependencies
```

**Python 3.13 compatibility issues**
```bash
# Use minimal setup which avoids problematic packages:
./setup-minimal.sh
```

### Backend Issues

**Error: "Video processor is not available"**
```bash
# Ensure your ml_stuff directory contains the processors
ls ml_stuff/processors/
# Should show: transcribe.py, segments.py, captions.py

# Check if the backend can import your modules
cd backend && source venv/bin/activate
python -c "import sys; sys.path.append('../'); from ml_stuff.processors import transcribe, segments, captions; print('âœ… Processors imported successfully')"
```

**Error: "ModuleNotFoundError: No module named 'ml_stuff'"**
```bash
# Make sure you're running from the project root directory
pwd  # Should show path ending with your project name
ls   # Should show both ml_stuff/ and backend/ directories
```

**Port 8000 already in use**
```bash
# Use a different port
uvicorn app.main:app --reload --port 8001
# Update frontend/src/services/apiClient.ts accordingly
```

### Frontend Issues

**Error: "Network error occurred"**
- Ensure the backend server is running on `http://localhost:8000`
- Check browser console for CORS errors
- Verify the API base URL in `frontend/src/services/apiClient.ts`

**Port 3000 already in use**
```bash
# Next.js will automatically prompt to use port 3001
# Or specify a different port:
npm run dev -- --port 3001
```

**Build errors**
```bash
# Clear Next.js cache
rm -rf .next
npm run dev
```

### General Issues

**Processing takes too long**
- Large YouTube videos can take several minutes to process
- Video download, transcription, and clip creation are CPU-intensive
- Check backend logs for progress updates
- Ensure sufficient disk space in `backend/app/output_clips/`

**Generated clips not loading**
- Check if files exist in `backend/app/output_clips/`
- Verify static file serving is working: `http://localhost:8000/clips/`
- Check browser console for 404 errors

**"yt-dlp not installed" error**
```bash
cd backend && source venv/bin/activate
pip install yt-dlp
```

**"moviepy not installed" error**
```bash
cd backend && source venv/bin/activate
pip install moviepy
```

**Whisper/Transcription errors**
```bash
# Install torch first (required for Whisper)
cd backend && source venv/bin/activate
pip install torch
pip install openai-whisper
```

**OpenAI API errors (caption generation)**
```bash
# Set your OpenAI API key
export OPENAI_API_KEY="your-api-key-here"
# Or create a .env file in the backend directory
echo "OPENAI_API_KEY=your-api-key-here" > backend/.env
```

**"No clips generated" but processing completes**
- Check if moviepy is installed and working
- Video clips might fail to create but processing info is still saved
- Check `backend/app/output_clips/` for `.txt` files with clip information

**Strange files with names like `=0.104.0`, `=2.0.0` appear**
- These are junk files created by typing `>` instead of `==` in pip commands
- They are automatically cleaned up by `./setup.sh` and `./start.sh`
- You can manually delete them with: `find . -name "=*" -type f -delete`
- They are ignored by Git (won't be committed)

## ğŸ”’ Environment Variables

### Backend
Create `backend/.env` for custom configuration:
```env
# Custom output directory (optional)
OUTPUT_DIR="/path/to/custom/output"

# API settings
HOST=0.0.0.0
PORT=8000
```

### Frontend
Create `frontend/.env.local` for custom API endpoint:
```env
NEXT_PUBLIC_API_BASE_URL=http://localhost:8000
```

## ğŸ§ª Development

### Backend Development
```bash
cd backend
# Run with auto-reload
uvicorn app.main:app --reload

# Run tests (if implemented)
pytest

# Format code
black app/
```

### Frontend Development
```bash
cd frontend
# Development server with hot reload
npm run dev

# Type checking
npm run lint

# Build for production
npm run build
```

## ğŸ“ˆ Production Deployment

### Backend
```bash
# Install production dependencies
pip install gunicorn

# Run with Gunicorn
gunicorn app.main:app -w 4 -k uvicorn.workers.UvicornWorker
```

### Frontend
```bash
# Build for production
npm run build

# Start production server
npm start
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit your changes: `git commit -m 'Add amazing feature'`
4. Push to the branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

**Need help?** Check the troubleshooting section above or open an issue on GitHub.
